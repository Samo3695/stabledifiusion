"""
LoRA Training Script pre Stable Diffusion
==========================================

Tento skript natr√©nuje LoRA model na va≈°om vlastnom datasete obr√°zkov.
LoRA sa potom pou≈æije v app-lite.py na generovanie v ≈°t√Ωle v√°≈°ho datasetu.

POU≈ΩITIE:
1. Upravte DATASET_PATH ni≈æ≈°ie
2. Pripravte dataset (15-30 obr√°zkov v prieƒçinku)
3. Spustite: python train_lora.py
4. Poƒçkajte 1-2 hodiny (RTX 4060)
5. V√Ωstup: lora_models/my_lora.safetensors

≈†TRUKT√öRA DATASETU:
dataset/
  ‚îú‚îÄ‚îÄ image_001.jpg
  ‚îú‚îÄ‚îÄ image_002.jpg
  ‚îî‚îÄ‚îÄ ...

Automaticky sa vygeneruj√∫ captions (popisy) pre ka≈æd√Ω obr√°zok.
"""

import os
import torch
from diffusers import StableDiffusionPipeline, DDPMScheduler
from transformers import CLIPTextModel, CLIPTokenizer
from PIL import Image
import torch.nn.functional as F
from tqdm import tqdm
from pathlib import Path
import numpy as np

# ==========================================
# NASTAVENIA - UPRAVTE PODƒΩA POTREBY
# ==========================================

# üìÅ CESTA K DATASETU (obr√°zky pre tr√©novanie)
DATASET_PATH = r"C:\Users\siven\Downloads\verzie\firstshot\1x"

# üéØ TRIGGER WORD (slovo ktor√© spust√≠ v√°≈° ≈°t√Ωl)
# Pou≈æite v prompte: "a 1x house, front view"
TRIGGER_WORD = "1x"

# üíæ V√ùSTUPN√ù S√öBOR
OUTPUT_NAME = "lora_1x"  # Vytvor√≠: lora_models/lora_1x.safetensors

# üîß TR√âNOVACIE PARAMETRE (pre RTX 4060 8GB)
LEARNING_RATE = 5e-5  # Bolo 1e-4, zn√≠≈æen√© pre stabilitu
MAX_TRAIN_STEPS = 5000  # Bolo 1500, V√ùRAZNE ZV√ù≈†EN√â pre lep≈°ie v√Ωsledky
TRAIN_BATCH_SIZE = 1
GRADIENT_ACCUMULATION_STEPS = 4  # Bolo 1, zv√Ω≈°en√© pre lep≈°iu stabilitu
RESOLUTION = 512  # 512x512 px
LORA_RANK = 64  # Bolo 32, zv√Ω≈°en√© pre v√§ƒç≈°iu kapacitu uƒçenia

# üèóÔ∏è BASE MODEL
# Odpor√∫ƒçan√© modely:
# - "CompVis/stable-diffusion-v1-4" (star≈°√≠, slab≈°√≠)
# - "runwayml/stable-diffusion-v1-5" (z√°kladn√Ω)
# - "SG161222/Realistic_Vision_V5.1_noVAE" (fotorealistick√Ω, najlep≈°√≠!)
BASE_MODEL = "SG161222/Realistic_Vision_V5.1_noVAE"

# üí¨ AUTOMATICK√ù CAPTION (popis obr√°zkov)
# Pou≈æije sa ak neexistuj√∫ .txt s√∫bory
DEFAULT_CAPTION = f"a {TRIGGER_WORD}, high quality, detailed"

# ==========================================
# K√ìD - NEMUS√çTE MENI≈§
# ==========================================

def setup_directories():
    """Vytvor√≠ potrebn√© prieƒçinky"""
    os.makedirs("lora_models", exist_ok=True)
    os.makedirs(DATASET_PATH, exist_ok=True)
    print(f"‚úÖ Prieƒçinky pripraven√©")
    print(f"üìÅ Dataset: {DATASET_PATH}")
    print(f"üíæ V√Ωstup: lora_models/{OUTPUT_NAME}.safetensors")

def load_dataset():
    """Naƒç√≠ta obr√°zky z datasetu"""
    image_extensions = {'.jpg', '.jpeg', '.png', '.webp'}
    image_paths = []
    
    for file in Path(DATASET_PATH).iterdir():
        if file.suffix.lower() in image_extensions:
            image_paths.append(file)
    
    if not image_paths:
        raise ValueError(f"‚ùå ≈Ωiadne obr√°zky v {DATASET_PATH}!")
    
    print(f"‚úÖ N√°jden√Ωch {len(image_paths)} obr√°zkov")
    return image_paths

def get_caption(image_path):
    """
    Vygeneruje caption z n√°zvu s√∫boru.
    Pr√≠klad: 'egypt_palace_gold.jpg' -> 'egypt palace gold'
    
    Najprv sk√∫si naƒç√≠ta≈• .txt s√∫bor, ak neexistuje, pou≈æije n√°zov s√∫boru.
    """
    # Sk√∫s najprv .txt s√∫bor (ak existuje)
    txt_path = image_path.with_suffix('.txt')
    
    if txt_path.exists():
        with open(txt_path, 'r', encoding='utf-8') as f:
            caption = f.read().strip()
            print(f"   üìù Caption (z .txt): '{caption}'")
            return caption
    
    # Ak neexistuje .txt, pou≈æi n√°zov s√∫boru ako caption
    filename = os.path.basename(image_path)
    # Odstr√°≈à pr√≠ponu (.jpg, .png, .jpeg, atƒè.)
    caption = os.path.splitext(filename)[0]
    # Nahraƒè podƒçiarkovn√≠ky a pomlƒçky medzerami
    caption = caption.replace('_', ' ').replace('-', ' ')
    # Odstr√°≈à viacn√°sobn√© medzery
    caption = ' '.join(caption.split())
    
    print(f"   üìù Caption (z n√°zvu): '{caption}'")
    return caption

def prepare_image(image_path, size=512):
    """Priprav√≠ obr√°zok pre tr√©novanie"""
    image = Image.open(image_path).convert('RGB')
    
    # Resize na 512x512 (alebo in√∫ veƒækos≈•)
    image = image.resize((size, size), Image.Resampling.LANCZOS)
    
    # Konverzia na tensor
    image = torch.from_numpy(np.array(image)).float() / 127.5 - 1.0
    image = image.permute(2, 0, 1).unsqueeze(0)
    
    return image

def train_lora():
    """Hlavn√° tr√©novacia funkcia"""
    print("\n" + "="*50)
    print("üöÄ ≈†TART LoRA TR√âNOVANIA")
    print("="*50 + "\n")
    
    # 1. Nastavenie
    setup_directories()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üñ•Ô∏è  Zariadenie: {device}")
    
    if device.type == "cpu":
        print("‚ö†Ô∏è  UPOZORNENIE: Pou≈æ√≠vate CPU! Tr√©novanie bude VEƒΩMI pomal√© (dni).")
        print("   Odpor√∫ƒçam GPU (NVIDIA) pre r√Ωchle tr√©novanie.")
        response = input("   Pokraƒçova≈•? (y/n): ")
        if response.lower() != 'y':
            return
    
    # 2. Naƒç√≠tanie datasetu
    print("\nüìÅ Naƒç√≠tavam dataset...")
    image_paths = load_dataset()
    
    # 3. Naƒç√≠tanie base modelu
    print(f"\nüîÑ Naƒç√≠tavam base model: {BASE_MODEL}")
    print("   (Prv√Ωkr√°t sa stiahne ~4GB, ƒèalej z cache)")
    
    pipeline = StableDiffusionPipeline.from_pretrained(
        BASE_MODEL,
        torch_dtype=torch.float16 if device.type == "cuda" else torch.float32,
    )
    pipeline.to(device)
    
    unet = pipeline.unet
    text_encoder = pipeline.text_encoder
    tokenizer = pipeline.tokenizer
    vae = pipeline.vae
    
    print("‚úÖ Model naƒç√≠tan√Ω")
    
    # 4. Nastavenie LoRA layers (pou≈æit√≠m peft)
    print(f"\nüîß Konfigurujem LoRA (rank={LORA_RANK})...")
    
    from peft import LoraConfig, get_peft_model
    
    # Konfigur√°cia LoRA pre UNet
    lora_config = LoraConfig(
        r=LORA_RANK,
        lora_alpha=LORA_RANK,
        init_lora_weights="gaussian",
        target_modules=["to_k", "to_q", "to_v", "to_out.0"],
    )
    
    # Aplikuj LoRA na UNet
    unet = get_peft_model(unet, lora_config)
    unet.print_trainable_parameters()
    
    print("‚úÖ LoRA vrstvy pripraven√©")
    
    # 5. Optimizer
    optimizer = torch.optim.AdamW(
        unet.parameters(),
        lr=LEARNING_RATE,
        betas=(0.9, 0.999),
        weight_decay=1e-2,
        eps=1e-08,
    )
    
    # 6. Tr√©novanie
    print(f"\nüèãÔ∏è  ZAƒå√çNAM TR√âNOVANIE")
    print(f"   Kroky: {MAX_TRAIN_STEPS}")
    print(f"   Learning rate: {LEARNING_RATE}")
    print(f"   Batch size: {TRAIN_BATCH_SIZE}")
    print(f"   Oƒçak√°van√Ω ƒças: ~{MAX_TRAIN_STEPS // 15} min√∫t (na GPU)")
    print()
    
    global_step = 0
    progress_bar = tqdm(total=MAX_TRAIN_STEPS, desc="Tr√©novanie")
    
    unet.train()
    
    import numpy as np
    
    while global_step < MAX_TRAIN_STEPS:
        for image_path in image_paths:
            if global_step >= MAX_TRAIN_STEPS:
                break
            
            # Naƒç√≠taj obr√°zok a caption
            caption = get_caption(image_path)
            pixel_values = prepare_image(image_path, RESOLUTION).to(device)
            
            # Ensure correct dtype for VAE (match model precision)
            if device.type == 'cuda':
                pixel_values = pixel_values.half()  # Convert to float16 for GPU
            
            # Encode text
            text_inputs = tokenizer(
                caption,
                padding="max_length",
                max_length=tokenizer.model_max_length,
                truncation=True,
                return_tensors="pt",
            )
            text_input_ids = text_inputs.input_ids.to(device)
            
            with torch.no_grad():
                encoder_hidden_states = text_encoder(text_input_ids)[0]
                latents = vae.encode(pixel_values).latent_dist.sample()
                latents = latents * vae.config.scaling_factor
            
            # Sample noise
            noise = torch.randn_like(latents)
            timesteps = torch.randint(0, pipeline.scheduler.config.num_train_timesteps, (latents.shape[0],), device=device)
            timesteps = timesteps.long()
            
            # Add noise
            noisy_latents = pipeline.scheduler.add_noise(latents, noise, timesteps)
            
            # Predict noise
            model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample
            
            # Loss
            loss = F.mse_loss(model_pred.float(), noise.float(), reduction="mean")
            
            # Backward
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
            
            # Progress
            global_step += 1
            progress_bar.update(1)
            progress_bar.set_postfix({"loss": loss.item()})
    
    progress_bar.close()
    
    # 7. Ulo≈æenie
    print(f"\nüíæ Uklad√°m LoRA model...")
    output_path = f"lora_models/{OUTPUT_NAME}.safetensors"
    
    # Ulo≈æenie pomocou peft
    unet.save_pretrained(f"lora_models/{OUTPUT_NAME}")
    
    print(f"‚úÖ LoRA ulo≈æen√°: lora_models/{OUTPUT_NAME}/")
    
    # Alternat√≠vne: Export do safetensors form√°tu
    try:
        from peft import get_peft_model_state_dict
        from safetensors.torch import save_file
        
        lora_state_dict = get_peft_model_state_dict(unet)
        save_file(lora_state_dict, output_path)
        print(f"‚úÖ Safetensors export: {output_path}")
        print(f"üìä Veƒækos≈•: {os.path.getsize(output_path) / (1024*1024):.1f} MB")
    except Exception as export_err:
        print(f"‚ö†Ô∏è  Safetensors export preskoƒçen√Ω: {export_err}")
    
    # 8. Hotovo!
    print("\n" + "="*50)
    print("üéâ TR√âNOVANIE DOKONƒåEN√â!")
    print("="*50)
    print(f"\nüí° AKO POU≈ΩI≈§:")
    print(f"   1. LoRA je ulo≈æen√° v: lora_models/{OUTPUT_NAME}.safetensors")
    print(f"   2. V aplik√°cii vyberte t√∫to LoRA")
    print(f"   3. V prompte pou≈æite: '{TRIGGER_WORD}'")
    print(f"   4. Pr√≠klad: 'a {TRIGGER_WORD} house, red roof, front view'")
    print(f"\n‚ú® V√Ωsledky bud√∫ v ≈°t√Ωle v√°≈°ho datasetu!")

if __name__ == "__main__":
    try:
        train_lora()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Tr√©novanie preru≈°en√© pou≈æ√≠vateƒæom")
    except Exception as e:
        print(f"\n\n‚ùå CHYBA: {e}")
        import traceback
        traceback.print_exc()
