from flask import Flask, request, jsonify
from flask_cors import CORS
import torch
from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, DPMSolverMultistepScheduler, EulerAncestralDiscreteScheduler, EulerDiscreteScheduler
from PIL import Image
import io
import base64
import numpy as np
import os
from pathlib import Path
from remove_background import remove_black_background
from color_transform import shift_hue, adjust_saturation

# Sk√∫s importova≈• rembg (pre AI odstr√°nenie pozadia)
try:
    from rembg import remove as rembg_remove
    REMBG_AVAILABLE = True
    print("‚úÖ rembg kni≈ænica naƒç√≠tan√°")
except ImportError:
    REMBG_AVAILABLE = False
    print("‚ö†Ô∏è rembg kni≈ænica nie je dostupn√°, pou≈æije sa fallback")

app = Flask(__name__)
CORS(app)

# Prieƒçinok pre LoRA modely
LORA_DIR = "./lora_models"

# Prieƒçinok pre LoRA modely
LORA_DIR = "./lora_models"

# Pipelines map to support multiple models (loaded on demand)
pipelines = {
    # key -> { 'pipe': pipeline_obj, 'img2img': img2img_obj, 'version': str }
}

# Aktu√°lne naƒç√≠tan√° LoRA (aby sme vedeli ƒçi treba unfuse)
current_lora = {
    'name': None,
    'scale': None
}

def get_available_loras():
    """Vr√°ti zoznam dostupn√Ωch LoRA modelov"""
    if not os.path.exists(LORA_DIR):
        os.makedirs(LORA_DIR, exist_ok=True)
        return []
    
    loras = []
    for file in Path(LORA_DIR).iterdir():
        if file.suffix in ['.safetensors', '.pt', '.bin']:
            loras.append(file.stem)  # n√°zov bez pr√≠pony
    return loras

def load_lora_to_pipeline(pipe_entry, lora_name, lora_scale=0.9):
    """
    Naƒç√≠ta LoRA do pipeline.
    Ak u≈æ je nejak√° LoRA naƒç√≠tan√°, najprv ju unfuse.
    """
    global current_lora
    
    if not lora_name:
        # Ak je lora_name pr√°zdny, unfuse aktu√°lnu LoRA
        if current_lora['name']:
            print(f"üîÑ Unfusing aktu√°lnu LoRA: {current_lora['name']}")
            try:
                pipe_entry['pipe'].unfuse_lora()
                pipe_entry['img2img'].unfuse_lora()
            except:
                pass  # Mo≈æno nie je naƒç√≠tan√°
            current_lora['name'] = None
            current_lora['scale'] = None
        return
    
    lora_path = os.path.join(LORA_DIR, f"{lora_name}.safetensors")
    if not os.path.exists(lora_path):
        # Sk√∫sime .pt
        lora_path = os.path.join(LORA_DIR, f"{lora_name}.pt")
        if not os.path.exists(lora_path):
            raise FileNotFoundError(f"LoRA s√∫bor nen√°jden√Ω: {lora_name}")
    
    print(f"üé® Naƒç√≠tavam LoRA: {lora_name} (scale={lora_scale})")
    
    # Unfuse predch√°dzaj√∫cu LoRA ak existuje
    if current_lora['name']:
        print(f"üîÑ Unfusing predch√°dzaj√∫cu LoRA: {current_lora['name']}")
        try:
            pipe_entry['pipe'].unfuse_lora()
            pipe_entry['img2img'].unfuse_lora()
        except:
            pass
    
    # Naƒç√≠taj nov√∫ LoRA (zostane na tom istom device kde je pipeline)
    pipe_entry['pipe'].load_lora_weights(lora_path)
    pipe_entry['pipe'].fuse_lora(lora_scale=lora_scale)
    
    pipe_entry['img2img'].load_lora_weights(lora_path)
    pipe_entry['img2img'].fuse_lora(lora_scale=lora_scale)
    
    current_lora['name'] = lora_name
    current_lora['scale'] = lora_scale
    
    print(f"‚úÖ LoRA naƒç√≠tan√° a fused s scale={lora_scale}")

MODEL_REGISTRY = {
    'lite': {
        'id': 'CompVis/stable-diffusion-v1-4',
        'description': 'LITE (SD v1.4) - men≈°√≠, r√Ωchlej≈°√≠ model',
    },
    'realistic': {
        'id': 'SG161222/Realistic_Vision_V5.1_noVAE',
        'description': 'Realistic Vision V5.1 - fotorealistick√© detaily, najlep≈°ia kvalita',
    },
    'dreamshaper': {
        'id': 'Lykon/dreamshaper-8',
        'description': 'DreamShaper 8 - univerz√°lny, kvalitn√© detaily, mix ≈°t√Ωlov',
    },
    'absolutereality': {
        'id': 'Lykon/absolute-reality-1.81',
        'description': 'Absolute Reality - podobn√Ω DreamShaper, semi-realistick√Ω',
    },
    'epicrealism': {
        'id': 'emilianJR/epiCRealism',
        'description': 'Epic Realism - blend reality & concept art, podobn√Ω DreamShaper',
    },
    'majicmix': {
        'id': 'digiplay/majicMIX_realistic_v7',
        'description': 'MajicMix Realistic - mix reality & fantasy, perfektn√Ω pre img2img',
    },
    'full': {
        'id': 'runwayml/stable-diffusion-v1-5',
        'description': 'Full (SD v1.5) - v√§ƒç≈°√≠, vy≈°≈°ia kvalita',
    }
}


def load_pipeline(key: str):
    """Naƒç√≠ta a vr√°ti pipeline pre dan√Ω kƒæ√∫ƒç (lite/full). Nahr√°va sa on-demand."""
    global pipelines

    if key in pipelines:
        return pipelines[key]

    if key not in MODEL_REGISTRY:
        raise ValueError(f"Unknown model key: {key}")

    model_id = MODEL_REGISTRY[key]['id']
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ÔøΩ Naƒç√≠tavam model '{key}' -> {model_id} na zariadenie: {device}")

    try:
        pipe = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16 if device == 'cuda' else torch.float32,
            safety_checker=None,
            requires_safety_checker=False,
        )

        # Scheduler nastavenie - pre Realistic Vision pou≈æi≈• Euler
        if key == 'realistic':
            from diffusers import EulerAncestralDiscreteScheduler
            pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)
        elif key in ['dreamshaper', 'absolutereality', 'epicrealism', 'majicmix']:
            # Pre concept art modely pou≈æi≈• DDIM alebo Euler
            from diffusers import EulerDiscreteScheduler
            pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)
        else:
            pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
        
        pipe = pipe.to(device)
        if device == 'cuda':
            pipe.enable_attention_slicing()
            # Pridaj optimaliz√°cie pre VRAM
            try:
                pipe.enable_vae_slicing()  # VAE slicing ≈°etr√≠ pam√§≈• bez probl√©mov s device
                pipe.enable_vae_tiling()   # E≈°te lep≈°ie ≈°etr√≠ VRAM pri veƒæk√Ωch obr√°zkoch
            except:
                pass  # Star≈°ie verzie m√¥≈æu nema≈• tieto met√≥dy

        # Create img2img pipeline sharing components
        img2img = StableDiffusionImg2ImgPipeline(
            vae=pipe.vae,
            text_encoder=pipe.text_encoder,
            tokenizer=pipe.tokenizer,
            unet=pipe.unet,
            scheduler=pipe.scheduler,
            safety_checker=None,
            feature_extractor=pipe.feature_extractor,
        )
        img2img = img2img.to(device)

        pipelines[key] = {
            'pipe': pipe,
            'img2img': img2img,
            'version': key,
        }

        print(f"‚úÖ Model '{key}' naƒç√≠tan√Ω")
        return pipelines[key]

    except RuntimeError as oom:
        # GPU OOM or other runtime error
        print(f"‚ùå Chyba pri naƒç√≠tan√≠ modelu '{key}': {oom}")
        raise
    except Exception as e:
        print(f"‚ùå Neoƒçakovan√° chyba pri naƒç√≠tan√≠ modelu '{key}': {e}")
        raise

@app.route('/health', methods=['GET'])
def health():
    loaded = list(pipelines.keys())
    available_loras = get_available_loras()
    return jsonify({
        'status': 'ok',
        'models_loaded': loaded,
        'device': 'cuda' if torch.cuda.is_available() else 'cpu',
        'loras_available': available_loras,
        'current_lora': current_lora['name'],
    })

@app.route('/generate', methods=['POST'])
def generate():
    # model selection: 'lite' or 'full' (default: lite)
    model_key = (request.json or {}).get('model', 'lite')

    try:
        model_entry = load_pipeline(model_key)
    except Exception as e:
        return jsonify({'error': f'Nepodarilo sa naƒç√≠ta≈• po≈æadovan√Ω model: {e}'}), 500
    
    try:
        data = request.json
        prompt = data.get('prompt', '')
        negative_prompt = data.get('negative_prompt', '')
        input_image = data.get('input_image', '')  # Base64 obr√°zok
        
        # LoRA podpora
        lora_name = data.get('lora', '')  # N√°zov LoRA (bez pr√≠pony)
        lora_scale = data.get('lora_scale', 0.9)  # 0.0 - 1.0
        
        # Naƒç√≠taj LoRA ak je zadan√°
        try:
            if lora_name and lora_name != current_lora['name']:
                load_lora_to_pipeline(model_entry, lora_name, lora_scale)
            elif not lora_name and current_lora['name']:
                # Unfuse ak u≈æ nie je potrebn√°
                load_lora_to_pipeline(model_entry, '', 0.0)
        except Exception as lora_err:
            print(f"‚ö†Ô∏è  Chyba pri naƒç√≠tan√≠ LoRA: {lora_err}")
            return jsonify({'error': f'Chyba pri naƒç√≠tan√≠ LoRA: {lora_err}'}), 500
        
        # Limit steps for lite by default, but allow full to use higher default
        if model_key == 'lite':
            num_inference_steps = min(data.get('num_inference_steps', 30), 30)
        else:
            num_inference_steps = data.get('num_inference_steps', 50)
        guidance_scale = data.get('guidance_scale', 7.5)
        strength = data.get('strength', 0.75)  # Pre img2img - ako moc zmeni≈• obr√°zok
        
        # Rozmery obr√°zka (width, height)
        width = data.get('width', 512)
        height = data.get('height', 512)
        
        # Seed pre reprodukovateƒænos≈•
        seed = data.get('seed', None)
        
        # Zaokr√∫hli na n√°sobok 8 (po≈æiadavka SD)
        width = int(width // 8 * 8)
        height = int(height // 8 * 8)
        
        # Nastav generator ak m√°me seed
        generator = None
        if seed is not None:
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            generator = torch.Generator(device=device).manual_seed(int(seed))
            print(f"üé≤ Seed: {seed}")
        
        if not prompt:
            return jsonify({'error': 'Prompt je povinn√Ω'}), 400
        
        # Image-to-Image ak je nahrat√Ω obr√°zok
        if input_image:
            print(f"üñºÔ∏è Image-to-Image ({model_key}): {prompt[:50]}...")

            # Dek√≥duj base64 obr√°zok
            if ',' in input_image:
                input_image = input_image.split(',')[1]

            image_data = base64.b64decode(input_image)
            init_image = Image.open(io.BytesIO(image_data))
            
            # Zachovaj alpha kan√°l pre neskor≈°ie pou≈æitie
            has_alpha = False
            alpha_channel = None
            
            print(f"üñºÔ∏è  Vstup: {init_image.mode}")
            if init_image.mode == 'RGBA':
                has_alpha = True
                alpha_channel = init_image.split()[3]  # Ulo≈æ alpha kan√°l
                print("   ‚îî‚îÄ Detekovan√° priehƒæadnos≈• (RGBA)")
                # Konvertuj na RGB pre SD (s bielym pozad√≠m pre preview)
                rgb_image = Image.new('RGB', init_image.size, (255, 255, 255))
                rgb_image.paste(init_image, mask=alpha_channel)
                init_image = rgb_image
            elif init_image.mode != 'RGB':
                init_image = init_image.convert('RGB')

            # Zmeni≈• veƒækos≈• podƒæa po≈æadovan√Ωch rozmerov
            target_size = (width, height)
            init_image = init_image.resize(target_size)
            if has_alpha:
                alpha_channel = alpha_channel.resize(target_size, Image.Resampling.LANCZOS)

            # Use the requested img2img pipeline
            img2img_pipe = model_entry.get('img2img')
            if img2img_pipe is None:
                return jsonify({'error': 'Img2Img pipeline nie je dostupn√° pre po≈æadovan√Ω model'}), 500

            with torch.inference_mode():
                image = img2img_pipe(
                    prompt=prompt,
                    negative_prompt=negative_prompt,
                    image=init_image,
                    strength=strength,
                    num_inference_steps=num_inference_steps,
                    guidance_scale=guidance_scale,
                    generator=generator,
                ).images[0]
            
            # Automaticky odstr√°≈à ƒçierne pozadie a vytvor priehƒæadnos≈•
            if has_alpha:
                print("üîÑ Odstra≈àujem ƒçierne pozadie a vytv√°r√°m priehƒæadnos≈•...")
                # Odstr√°≈à ƒçierne pozadie z vygenerovan√©ho RGB obr√°zka
                image = remove_black_background(image, threshold=30)
            else:
                print("üí° Tip: Pre priehƒæadn√© pozadie nahrajte PNG s priehƒæadnos≈•ou")
        
        # Text-to-Image ak nie je obr√°zok
        else:
            print(f"üé® Text-to-Image ({model_key}): {prompt[:50]}... [{width}x{height}]")
            pipe = model_entry.get('pipe')
            if pipe is None:
                return jsonify({'error': 'Text-to-Image pipeline nie je dostupn√° pre po≈æadovan√Ω model'}), 500

            with torch.inference_mode():
                image = pipe(
                    prompt=prompt,
                    negative_prompt=negative_prompt,
                    num_inference_steps=num_inference_steps,
                    guidance_scale=guidance_scale,
                    width=width,
                    height=height,
                    generator=generator,
                ).images[0]
        
        buffer = io.BytesIO()
        image.save(buffer, format='PNG')
        img_base64 = base64.b64encode(buffer.getvalue()).decode()
        
        print("‚úÖ Hotovo!")
        
        return jsonify({
            'image': f'data:image/png;base64,{img_base64}',
            'prompt': prompt
        })
        
    except Exception as e:
        print(f"‚ùå Chyba: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/remove-background', methods=['POST'])
def remove_background_endpoint():
    """Odstr√°ni pozadie z obr√°zka pomocou AI (rembg) alebo fallback met√≥dou"""
    try:
        data = request.json
        image_data = data.get('image')
        use_ai = data.get('use_ai', True)  # Pou≈æi≈• AI (rembg) alebo star√∫ met√≥du
        threshold = data.get('threshold', 30)  # Pre fallback met√≥du
        
        if not image_data:
            return jsonify({'error': 'Ch√Ωba obr√°zok'}), 400
        
        # Dek√≥duj base64 obr√°zok
        if 'base64,' in image_data:
            image_data = image_data.split('base64,')[1]
        
        image_bytes = base64.b64decode(image_data)
        image = Image.open(io.BytesIO(image_bytes))
        
        # Konvertuj na RGB ak je potrebn√©
        if image.mode == 'RGBA':
            rgb_image = Image.new('RGB', image.size, (255, 255, 255))
            rgb_image.paste(image, mask=image.split()[3])
            image = rgb_image
        elif image.mode != 'RGB':
            image = image.convert('RGB')
        
        if use_ai and REMBG_AVAILABLE:
            print("ü§ñ Odstra≈àujem pozadie pomocou AI (rembg)...")
            # Pou≈æij rembg pre AI odstr√°nenie pozadia
            result_image = rembg_remove(image)
        else:
            print(f"üîÑ Odstra≈àujem ƒçierne pozadie (prah: {threshold})...")
            result_image = remove_black_background(image, threshold=threshold)
        
        # Konvertuj sp√§≈• na base64
        buffer = io.BytesIO()
        result_image.save(buffer, format='PNG')
        img_base64 = base64.b64encode(buffer.getvalue()).decode()
        
        print("‚úÖ Pozadie odstr√°nen√©!")
        
        return jsonify({
            'image': f'data:image/png;base64,{img_base64}'
        })
        
    except Exception as e:
        print(f"‚ùå Chyba pri odstra≈àovan√≠ pozadia: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/adjust-hue', methods=['POST'])
def adjust_hue_endpoint():
    """Zmen√≠ farebn√Ω odtie≈à obr√°zka bez straty kvality"""
    try:
        data = request.json
        image_data = data.get('image')
        hue_shift = data.get('hue_shift', 0)  # -180 a≈æ +180 stup≈àov
        
        if not image_data:
            return jsonify({'error': 'Ch√Ωba obr√°zok'}), 400
        
        # Dek√≥duj base64 obr√°zok
        if 'base64,' in image_data:
            image_data = image_data.split('base64,')[1]
        
        image_bytes = base64.b64decode(image_data)
        image = Image.open(io.BytesIO(image_bytes))
        
        print(f"üé® Men√≠m farebn√Ω odtie≈à (posun: {hue_shift}¬∞)...")
        
        # Zme≈à odtie≈à
        result_image = shift_hue(image, hue_shift)
        
        # Konvertuj sp√§≈• na base64
        buffer = io.BytesIO()
        result_image.save(buffer, format='PNG')
        img_base64 = base64.b64encode(buffer.getvalue()).decode()
        
        print("‚úÖ Odtie≈à zmenen√Ω!")
        
        return jsonify({
            'image': f'data:image/png;base64,{img_base64}'
        })
        
    except Exception as e:
        print(f"‚ùå Chyba pri zmene odtie≈àa: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    print("=" * 60)
    print("üöÄ Stable Diffusion Backend (multi-model, on-demand)")
    print("=" * 60)
    # Pokus√≠me sa prednaƒç√≠ta≈• LITE model pre r√Ωchlej≈°√≠ start (ak je to mo≈æn√©)
    try:
        load_pipeline('lite')
        print("\nüåê Prednaƒç√≠tan√Ω LITE model (ak bol √∫spe≈°ne stiahnut√Ω)")
    except Exception as e:
        print(f"\n‚ö†Ô∏è  Nepodarilo sa prednaƒç√≠ta≈• LITE model: {e}")

    print("\nüåê Server pripraven√Ω!")
    print("üìç URL: http://localhost:5000")
    print("‚ö° Podpora pre 'lite' a 'full' modely (na po≈æiadanie)")
    print("=" * 60)
    app.run(host='0.0.0.0', port=5000, debug=False)
