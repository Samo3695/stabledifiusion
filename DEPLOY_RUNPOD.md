# ğŸš€ Deploy na RunPod

KompletnÃ½ nÃ¡vod na nasadenie Stable Diffusion aplikÃ¡cie na RunPod.

## ğŸ“‹ PrÃ­prava

### 1. RegistrÃ¡cia na RunPod
1. ChoÄ na [runpod.io](https://runpod.io)
2. Vytvor ÃºÄet
3. Pridaj kredit ($10-20 na zaÄiatok)

### 2. Docker Image sa builduje automaticky! ğŸ‰

**GitHub Actions automaticky zbuilduje a nahrÃ¡ Docker image pri kaÅ¾dom pushu na `main` branch.**

Image je dostupnÃ½ na:
```
ghcr.io/siven-samuel/stabledifiusion:latest
```

**Ako to funguje:**
1. Push kÃ³d na GitHub â†’ automatickÃ½ build
2. GitHub Actions zbuilduje Docker image
3. Image sa nahrÃ¡ na GitHub Container Registry
4. MÃ´Å¾eÅ¡ ho hneÄ pouÅ¾iÅ¥ v RunPod!

**Kontrola buildu:**
- ChoÄ na GitHub repo â†’ **Actions tab**
- UvidÃ­Å¡ "Build and Push Docker Image" workflow
- ZelenÃ¡ fajka âœ… = build ÃºspeÅ¡nÃ½

**ManuÃ¡lne spustenie buildu:**
1. ChoÄ na **Actions** â†’ **Build and Push Docker Image**
2. Klikni **Run workflow** â†’ **Run workflow**

## ğŸ¯ Deploy na RunPod

### PouÅ¾itie automaticky zbuildovanÃ©ho image

1. **Vytvor Template:**
   - V RunPod dashboard klikni na **Templates** â†’ **New Template**
   - **Container Image:** `ghcr.io/siven-samuel/stabledifiusion:latest`
   - **Container Disk:** 20 GB (min)
   - **Volume Disk:** 50 GB (pre modely cache)
   - **Expose HTTP Ports:** `5000`
   - **Environment Variables:**
     ```
     HF_HOME=/workspace/.cache/huggingface
     CUDA_VISIBLE_DEVICES=0
     ```

2. **Deploy Pod:**
   - ChoÄ na **Pods** â†’ **Deploy**
   - Vyber svoj template
   - **GPU Type:** RTX 4090 (najlepÅ¡Ã­ pomer cena/vÃ½kon) alebo RTX 3090
   - **Region:** NajbliÅ¾Å¡ia (Europe/US)
   - Klikni **Deploy**

3. **PrÃ­stup:**
   - Po deploy dostaneÅ¡ **Public IP** a **Port**
   - Backend: `http://TVOJA_IP:5000`
   - Testuj: `http://TVOJA_IP:5000/health`

### MetÃ³da 2: Pomocou RunPod CLI

```bash
# NainÅ¡taluj RunPod CLI
pip install runpod

# Login
runpod config

# Deploy
runpod deploy \
  --name stablediffusion \
  --image ghcr.io/siven-samuel/stabledifiusion:latest \
  --gpu-type "NVIDIA RTX 4090" \
  --gpu-count 1 \
  --ports 5000:5000 \
  --volume 50 \
  --env HF_HOME=/workspace/.cache/huggingface
```

## ğŸ”§ KonfigurÃ¡cia Backend

### Pridaj CORS pre vzdialenÃ½ prÃ­stup

Uprav `sd-backend/app-lite.py`:

```python
from flask_cors import CORS

app = Flask(__name__)
CORS(app, origins=["*"])  # Pre produkciu Å¡pecifikuj domÃ©ny
```

### Environment Variables

V RunPod Template pridaj:

```
HF_HOME=/workspace/.cache/huggingface
FLASK_HOST=0.0.0.0
FLASK_PORT=5000
TRANSFORMERS_CACHE=/workspace/.cache/huggingface
```

## ğŸ“Š Monitorovanie

### Logy v RunPod

```bash
# V RunPod Web Terminal
cd /app/sd-backend
tail -f logs/app.log
```

### Health Check

```bash
curl http://TVOJA_IP:5000/health
```

OdpoveÄ:
```json
{
  "status": "running",
  "models_loaded": ["lite"],
  "device": "cuda",
  "loras_available": ["lora_1x", "my_lora"]
}
```

## ğŸ’° NÃ¡klady (RTX 4090)

- **On-Demand:** $0.44/hod
- **1000 obrÃ¡zkov/deÅˆ:** ~$0.73/deÅˆ = **~$22/mes**
- **5000 obrÃ¡zkov/deÅˆ:** ~$3.60/deÅˆ = **~$108/mes**

**Tip:** Nastav **Auto-Stop** keÄ nepouÅ¾Ã­vaÅ¡ (Å¡etrÃ­ ~50% nÃ¡kladov)

## ğŸ” BezpeÄnosÅ¥

### 1. Pridaj API Key autentifikÃ¡ciu

V `app-lite.py`:

```python
from functools import wraps
from flask import request

API_KEY = os.getenv("API_KEY", "your-secret-key")

def require_api_key(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        key = request.headers.get('X-API-Key')
        if key != API_KEY:
            return {"error": "Unauthorized"}, 401
        return f(*args, **kwargs)
    return decorated_function

@app.route('/generate', methods=['POST'])
@require_api_key
def generate():
    # ...
```

### 2. Rate Limiting

```bash
pip install flask-limiter
```

```python
from flask_limiter import Limiter

limiter = Limiter(
    app,
    key_func=lambda: request.remote_addr,
    default_limits=["100 per hour"]
)

@app.route('/generate', methods=['POST'])
@limiter.limit("10 per minute")
def generate():
    # ...
```

## ğŸš€ Frontend Deploy (Vercel/Netlify)

### 1. Uprav API URL

V `sd-app/src/components/ImageGenerator.vue`:

```javascript
const API_URL = import.meta.env.VITE_API_URL || 'http://localhost:5000/generate'
```

### 2. Build frontend

```bash
cd sd-app
yarn build
```

### 3. Deploy na Vercel

```bash
npm i -g vercel
cd sd-app
vercel deploy
```

Environment variables:
```
VITE_API_URL=http://RUNPOD_IP:5000
```

## ğŸ“ Checklist

- [ ] GitHub Actions workflow funguje (zelenÃ¡ fajka v Actions tab)
- [ ] Docker image je na `ghcr.io/siven-samuel/stabledifiusion:latest`
- [ ] RunPod template vytvorenÃ½
- [ ] Pod deployed a running
- [ ] `/health` endpoint funguje
- [ ] Test generovania obrÃ¡zka
- [ ] CORS nakonfigurovanÃ©
- [ ] API key autentifikÃ¡cia (optional)
- [ ] Rate limiting (optional)
- [ ] Frontend deployed (Vercel/Netlify)
- [ ] Auto-stop nastavenÃ½ (Å¡etrÃ­ peniaze)

## ğŸ†˜ Troubleshooting

### GitHub Actions build zlyhÃ¡va
```bash
# Skontroluj Actions tab na GitHub
# Klikni na failed workflow â†’ pozri logy
```

### RunPod nemÃ´Å¾e stiahnuÅ¥ image
- Image musÃ­ byÅ¥ **public**
- ChoÄ na GitHub repo â†’ **Packages** â†’ tvoj package
- Klikni **Package settings** â†’ **Change visibility** â†’ **Public**

### Container nezapÃ­na
```bash
# Skontroluj logy v RunPod Web Terminal
docker logs <container_id>
```

### CUDA not available
```bash
# Skontroluj GPU
nvidia-smi
```

### Models nesÅ¥ahuje
```bash
# Skontroluj HF_HOME
echo $HF_HOME
ls -la /workspace/.cache/huggingface
```

### Port nie je dostupnÃ½
- Skontroluj Å¾e port 5000 je v **Exposed Ports**
- Skontroluj firewall v RunPod settings

## ğŸ“ Kontakt & Support

- RunPod Discord: [discord.gg/runpod](https://discord.gg/runpod)
- GitHub Issues: `github.com/siven-samuel/stabledifiusion/issues`

---

**Ready to deploy?** ğŸš€

1. **Commit a push zmeny** (GitHub Actions automaticky zbuilduje image)
2. **PoÄkaj ~10-15 min** na dokonÄenie buildu (sleduj v Actions tab)
3. **Nastav RunPod template** s `ghcr.io/siven-samuel/stabledifiusion:latest`
4. **Deploy!**

**Å½iadne lokÃ¡lne buildovanie potrebnÃ©!** âœ¨

